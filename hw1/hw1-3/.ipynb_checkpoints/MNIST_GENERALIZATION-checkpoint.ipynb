{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import SGD, Adadelta, Adam\n",
    "from keras.layers import Input, Flatten, Dense, Dropout\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import keras\n",
    "portion_len = 10\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MODEL(object):\n",
    "    def __init__(self,parameters_coef, width = 28, height = 28):\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.parameters_coef = parameters_coef\n",
    "        \n",
    "        self.shape = (self.width, self.height)\n",
    "        self.optimizer =  SGD(lr=0.01, momentum=0.9, decay=1e-8, nesterov=False)\n",
    "        \n",
    "        self.model = self.__model()\n",
    "        self.model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        \n",
    "    def __model(self):\n",
    "        model = keras.models.Sequential([\n",
    "          keras.layers.Flatten(input_shape = self.shape),\n",
    "          keras.layers.Dense(math.floor(self.parameters_coef*512), activation='relu'),\n",
    "          keras.layers.Dropout(0.2),\n",
    "          keras.layers.Dense(10, activation='softmax')\n",
    "        ])\n",
    "        model.summary()\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    \n",
    "    def train(self, x_train, y_train, epochs = 10):\n",
    "        callbacks = [\n",
    "            keras.callbacks.EarlyStopping(monitor='loss', patience=5, verbose=0)\n",
    "            #ModelCheckpoint(kfold_weights_path, monitor='val_loss', save_best_only=True, verbose=0),\n",
    "        ]\n",
    "        history = self.model.fit(x_train, y_train, epochs=epochs, callbacks=callbacks)\n",
    "        \n",
    "        loss = history.history['loss']\n",
    "        accuracy = history.history['acc']\n",
    "        self.loss = loss\n",
    "        self.acc = accuracy\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU found\n",
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.2170 - acc: 0.9360\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.0962 - acc: 0.9702\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.0682 - acc: 0.9789\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 5s 78us/step - loss: 0.0558 - acc: 0.9817\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 5s 88us/step - loss: 0.0432 - acc: 0.9858\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.0374 - acc: 0.9877\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.0310 - acc: 0.9897\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 0.0278 - acc: 0.9910\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.0250 - acc: 0.9917\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.0223 - acc: 0.9923\n",
      "10000/10000 [==============================] - 0s 20us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_2 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              803840    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 814,090\n",
      "Trainable params: 814,090\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.1995 - acc: 0.9390\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: 0.0890 - acc: 0.9724\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.0629 - acc: 0.9799\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.0503 - acc: 0.9839\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.0383 - acc: 0.9868\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.0361 - acc: 0.9886\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.0292 - acc: 0.9901\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.0251 - acc: 0.9915\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.0240 - acc: 0.9924\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 0.0212 - acc: 0.9931\n",
      "10000/10000 [==============================] - 0s 22us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_3 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1536)              1205760   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                15370     \n",
      "=================================================================\n",
      "Total params: 1,221,130\n",
      "Trainable params: 1,221,130\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.1955 - acc: 0.9412\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0877 - acc: 0.9728\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.0633 - acc: 0.9796\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 0.0502 - acc: 0.9838\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.0418 - acc: 0.9862\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 0.0365 - acc: 0.9883\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0320 - acc: 0.9903\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: 0.0302 - acc: 0.9903\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 5s 77us/step - loss: 0.0262 - acc: 0.9920\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.0242 - acc: 0.9925\n",
      "10000/10000 [==============================] - 0s 23us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_4 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2048)              1607680   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                20490     \n",
      "=================================================================\n",
      "Total params: 1,628,170\n",
      "Trainable params: 1,628,170\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 0.1912 - acc: 0.9413\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 0.0896 - acc: 0.9715\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 0.0624 - acc: 0.9799\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 0.0502 - acc: 0.9837\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 0.0404 - acc: 0.9871\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 0.0365 - acc: 0.9882\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 0.0341 - acc: 0.9894\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 0.0279 - acc: 0.9915\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.0247 - acc: 0.9919\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.0263 - acc: 0.9919\n",
      "10000/10000 [==============================] - 0s 25us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_5 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2560)              2009600   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 2560)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                25610     \n",
      "=================================================================\n",
      "Total params: 2,035,210\n",
      "Trainable params: 2,035,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 0.1890 - acc: 0.9418\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 8s 137us/step - loss: 0.0885 - acc: 0.9722\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 0.0640 - acc: 0.9792\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 0.0524 - acc: 0.9837\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 0.0417 - acc: 0.9867\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 9s 143us/step - loss: 0.0362 - acc: 0.9884\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 0.0323 - acc: 0.9898\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 8s 136us/step - loss: 0.0291 - acc: 0.9910\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 7s 125us/step - loss: 0.0295 - acc: 0.9909\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 8s 140us/step - loss: 0.0230 - acc: 0.9931\n",
      "10000/10000 [==============================] - 0s 26us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_6 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 3072)              2411520   \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                30730     \n",
      "=================================================================\n",
      "Total params: 2,442,250\n",
      "Trainable params: 2,442,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 9s 143us/step - loss: 0.1908 - acc: 0.9418\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 9s 152us/step - loss: 0.0861 - acc: 0.9738\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 9s 152us/step - loss: 0.0650 - acc: 0.9793\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 9s 152us/step - loss: 0.0508 - acc: 0.9842\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0427 - acc: 0.9867\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 0.0376 - acc: 0.9883\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 9s 143us/step - loss: 0.0334 - acc: 0.9894\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 9s 151us/step - loss: 0.0310 - acc: 0.9906\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 9s 147us/step - loss: 0.0295 - acc: 0.9913\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 0.0253 - acc: 0.9928\n",
      "10000/10000 [==============================] - 0s 28us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_7 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 3584)              2813440   \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 3584)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                35850     \n",
      "=================================================================\n",
      "Total params: 2,849,290\n",
      "Trainable params: 2,849,290\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 9s 145us/step - loss: 0.1883 - acc: 0.9420\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 9s 150us/step - loss: 0.0898 - acc: 0.9727\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 10s 172us/step - loss: 0.0650 - acc: 0.9802\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 9s 153us/step - loss: 0.0503 - acc: 0.9836\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 9s 154us/step - loss: 0.0454 - acc: 0.9859\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 8s 132us/step - loss: 0.0397 - acc: 0.9880\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 8s 139us/step - loss: 0.0348 - acc: 0.9896\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 9s 145us/step - loss: 0.0307 - acc: 0.9911\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 8s 139us/step - loss: 0.0292 - acc: 0.9916\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 8s 132us/step - loss: 0.0295 - acc: 0.9918\n",
      "10000/10000 [==============================] - 0s 29us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_8 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 4096)              3215360   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 10)                40970     \n",
      "=================================================================\n",
      "Total params: 3,256,330\n",
      "Trainable params: 3,256,330\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 9s 152us/step - loss: 0.1876 - acc: 0.9422\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.0915 - acc: 0.9720\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 9s 151us/step - loss: 0.0677 - acc: 0.9793\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.0521 - acc: 0.9839\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.0452 - acc: 0.9858\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 9s 151us/step - loss: 0.0391 - acc: 0.9878\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.0365 - acc: 0.9889\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.0315 - acc: 0.9912\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 11s 178us/step - loss: 0.0318 - acc: 0.9906\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.0292 - acc: 0.9916\n",
      "10000/10000 [==============================] - 0s 30us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_9 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 4608)              3617280   \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 10)                46090     \n",
      "=================================================================\n",
      "Total params: 3,663,370\n",
      "Trainable params: 3,663,370\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.1890 - acc: 0.9420\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 10s 173us/step - loss: 0.0907 - acc: 0.9715\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 11s 180us/step - loss: 0.0672 - acc: 0.9786\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 10s 165us/step - loss: 0.0520 - acc: 0.9838\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 11s 188us/step - loss: 0.0482 - acc: 0.9856\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 10s 170us/step - loss: 0.0376 - acc: 0.9886\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.0376 - acc: 0.9884\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 10s 170us/step - loss: 0.0371 - acc: 0.9896\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 11s 186us/step - loss: 0.0315 - acc: 0.9913\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.0252 - acc: 0.9929\n",
      "10000/10000 [==============================] - 0s 41us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_10 (Flatten)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 5120)              4019200   \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 5120)              0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                51210     \n",
      "=================================================================\n",
      "Total params: 4,070,410\n",
      "Trainable params: 4,070,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.1896 - acc: 0.9418\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 11s 185us/step - loss: 0.0923 - acc: 0.9716\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 11s 180us/step - loss: 0.0700 - acc: 0.9788\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 11s 188us/step - loss: 0.0560 - acc: 0.9831\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 10s 170us/step - loss: 0.0449 - acc: 0.9864\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 11s 183us/step - loss: 0.0423 - acc: 0.9873\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 12s 195us/step - loss: 0.0392 - acc: 0.9884\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 11s 179us/step - loss: 0.0313 - acc: 0.9906\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 11s 188us/step - loss: 0.0327 - acc: 0.9909\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 10s 167us/step - loss: 0.0308 - acc: 0.9915\n",
      "10000/10000 [==============================] - 0s 37us/step\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    if tf.test.gpu_device_name():\n",
    "        print('GPU found')\n",
    "    else:\n",
    "        print(\"No GPU found\")\n",
    "    (x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "    x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "#     y_train = np_utils.to_categorical(y_train, num_classes=10)\n",
    "#     y_test = np_utils.to_categorical(y_test, num_classes=10)\n",
    "    print(x_train.shape)\n",
    "    print(y_train.shape)\n",
    "    train_acc = []\n",
    "    train_loss = []\n",
    "    \n",
    "    eval_acc = []\n",
    "    eval_loss = []\n",
    "    \n",
    "    for i in range(portion_len):\n",
    "        to_len = math.floor(len(x_train)*(i+1)/portion_len)\n",
    "        my_mnist = MODEL(parameters_coef = (i+1))\n",
    "        file_name = \"MNIST_GENERALIZATION\" + str(i) + \".h5\"\n",
    "        my_mnist.train(x_train, y_train)\n",
    "        my_mnist.model.save(file_name)\n",
    "        train_loss.append(my_mnist.loss)\n",
    "        train_acc.append(my_mnist.acc)\n",
    "        \n",
    "        loss,acc = my_mnist.model.evaluate(x_test, y_test)\n",
    "        eval_loss.append(loss)\n",
    "        eval_acc.append(acc)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    plt.scatter(np.arange(portion_len) ,train_loss[-1], label='train')\n",
    "    plt.scatter(np.arange(portion_len) ,eval_loss, label='test')\n",
    "\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.xlabel('coef of parameters')\n",
    "    plt.ylabel('loss')\n",
    "    plt.show()\n",
    "    plt.savefig('MNIST_GENERALIZATION_LOSS.png')\n",
    "    np.save(\"MNIST_GENERALIZATION_TRAIN_LOSS\",np.array(train_loss))\n",
    "    np.save(\"MNIST_GENERALIZATION_TEST_LOSS\",np.array(eval_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must be the same size",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-dd74fd741e47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mportion_len\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mportion_len\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0meval_acc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MNIST_GENERALIZATION_TRAIN_ACC\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MNIST_GENERALIZATION_TEST_ACC\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'upper right'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML_env/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, data, **kwargs)\u001b[0m\n\u001b[1;32m   2862\u001b[0m         \u001b[0mvmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlinewidths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2863\u001b[0m         verts=verts, edgecolors=edgecolors, **({\"data\": data} if data\n\u001b[0;32m-> 2864\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2865\u001b[0m     \u001b[0msci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2866\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML_env/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1808\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1810\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[0;32m~/anaconda3/envs/ML_env/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs)\u001b[0m\n\u001b[1;32m   4180\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4181\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4182\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x and y must be the same size\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4184\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must be the same size"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "    plt.scatter(np.arange(portion_len) ,train_acc[-1], label='train')\n",
    "    plt.scatter(np.arange(portion_len) ,eval_acc, label='test')\n",
    "    np.save(\"MNIST_GENERALIZATION_TRAIN_ACC\",np.array(train_acc))\n",
    "    np.save(\"MNIST_GENERALIZATION_TEST_ACC\",np.array(eval_acc))\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.xlabel('coef of parameters')\n",
    "    plt.ylabel('acc')\n",
    "    plt.show()\n",
    "    plt.savefig('MNIST_GENERALIZATION_ACC.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
