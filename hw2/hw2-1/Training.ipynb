{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Softmax, Dense\n",
    "from tensorflow.keras.layers import CuDNNGRU, CuDNNLSTM\n",
    "from tensorflow.keras.layers import Bidirectional, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfilename = 'training_data/id.txt'\n",
    "datadirname = 'training_data/feat/'\n",
    "labelfilename = 'training_label.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement Sent2Seq\n",
    "# hyperparameter: min count > 3 (discard terms with freq <= 3)\n",
    "def Sent2Seq(sent):\n",
    "    return [0] * len(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "BOS = \"<bos>\"\n",
    "EOS = \"<eos>\"\n",
    "\n",
    "# loading training data\n",
    "encode_x = []\n",
    "video_id = {}\n",
    "for i,lb in enumerate(open(idfilename)):\n",
    "    x = np.load(datadirname + lb)\n",
    "    encode_x.append(x)\n",
    "    video_id[lb] = i\n",
    "    \n",
    "TRAIN_SZ = len(encode_x)\n",
    "decode_x = [[]]*TRAIN_SZ\n",
    "decode_y = [[]]*TRAIN_SZ\n",
    "\n",
    "# loading decoder data\n",
    "rawlabels = json.load(open(labelfilename, 'r'))\n",
    "for data in rawlabels:\n",
    "    index = video_id[data['id']]\n",
    "    sent =  data['caption'][0] # select one sentence for now\n",
    "    # TODO: implement Sent2Seq\n",
    "    decode_x[index] = Sent2Seq(BOS+sent)\n",
    "    decode_y[index] = Sent2Seq(sent+EOS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "# data1 = pad_sequences(data1, maxlen=MAX_IN_LEN, padding='pre', truncating='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SZ = 10000 # maybe? need statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "EncoderInput (InputLayer)       (None, 80, 4096)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "DecoderInput (InputLayer)       (None, 50, 10000)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Encoder (CuDNNGRU)              [(None, 256), (None, 3343872     EncoderInput[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Decoder (CuDNNGRU)              (None, 50, 256)      7878144     DecoderInput[0][0]               \n",
      "                                                                 Encoder[0][1]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, 50, 10000)    2570000     Decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 13,792,016\n",
      "Trainable params: 13,792,016\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Using sparse_categorical_crossentropy, we only need to pass integers as input to decoder.\n",
    "MAX_SEQ_LEN = 50\n",
    "EncoderDIM = 256\n",
    "DecoderDIM = 256\n",
    "\n",
    "# Layers\n",
    "t_encoder_input = Input(shape=(80, 4096), name=\"EncoderInput\")\n",
    "t_decoder_input = Input(shape=(MAX_SEQ_LEN, VOCAB_SZ), name=\"DecoderInput\")\n",
    "L_encoder = CuDNNGRU(EncoderDIM, return_state=True, name='Encoder')\n",
    "L_decoder = CuDNNGRU(DecoderDIM, return_sequences=True, name='Decoder')\n",
    "L_Dense = Dense(VOCAB_SZ, name=\"Dense\", activation='softmax')\n",
    "# L_SM = Softmax(axis=-1, name=\"Softmax\")\n",
    "\n",
    "# tensors\n",
    "t_encoder_outputs, state_h = L_encoder(t_encoder_input)\n",
    "t_decoder_outputs = L_decoder(t_decoder_input, initial_state=state_h)\n",
    "t_out_probs = TimeDistributed(L_Dense)(t_decoder_outputs)\n",
    "\n",
    "\n",
    "model = Model(inputs=[t_encoder_input, t_decoder_input], outputs=t_out_probs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(lr=1e-3)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(x=[encode_x, decode_x], y=decode_y, batch_size=128, epochs=200) #callbacks=[]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
