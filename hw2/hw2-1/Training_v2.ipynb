{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Softmax, Dense\n",
    "from tensorflow.keras.layers import CuDNNGRU, CuDNNLSTM\n",
    "from tensorflow.keras.layers import Bidirectional, TimeDistributed, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import json\n",
    "import nltk\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfilename = 'training_data/id.txt'\n",
    "datadirname = 'training_data/feat/'\n",
    "labelfilename = 'training_label.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dictionary\n",
    "\n",
    "with open(\"DIC_word_index.json\") as f:\n",
    "    DIC_word_index = json.load(f)\n",
    "    \n",
    "with open(\"DIC_index_word.json\") as f:\n",
    "    DIC_index_word = json.load(f)\n",
    "\n",
    "#DIC_index_word = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement Sent2Seq\n",
    "# hyperparameter: min count > 3 (discard terms with freq <= 3)\n",
    "def Sent2Seq(sent):\n",
    "    #print(sent)\n",
    "    tokens = word_tokenize(sent.lower())\n",
    "    ret = []\n",
    "    #print(tokens)\n",
    "    for word in tokens:\n",
    "        #print(word)\n",
    "        ret.append(DIC_word_index[word])\n",
    "    #input(\"\")\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BOS = \"<bos>\"\n",
    "EOS = \"<eos>\"\n",
    "PAD = \"<pad>\"\n",
    "UNK = \"<unk>\"\n",
    "\n",
    "BOS_index = DIC_word_index[BOS]\n",
    "EOS_index = DIC_word_index[EOS]\n",
    "\n",
    "# loading training data\n",
    "encode_x = []\n",
    "video_id = {}\n",
    "\n",
    "for i,lb in enumerate(open(idfilename)):\n",
    "    #lb contains '\\n', therefore lb[:-1]\n",
    "    lb = lb[:-1]\n",
    "    video_id[lb] = i\n",
    "\n",
    "TRAIN_SZ = len(video_id)\n",
    "decode_x = [[]]*TRAIN_SZ\n",
    "decode_y = [[]]*TRAIN_SZ\n",
    "\n",
    "MAX_SEQ_LEN = 0;\n",
    "\n",
    "pad = [0] * 80\n",
    "\n",
    "\n",
    "\n",
    "# loading decoder data\n",
    "rawlabels = json.load(open(labelfilename, 'r'))\n",
    "for data in rawlabels:\n",
    "    \n",
    "    index = video_id[data['id']]\n",
    "    #print(index)\n",
    "    sent =  data['caption'][0] # select one sentence for now\n",
    "    # TODO: implement Sent2Seq\n",
    "\n",
    "    decode_x[index] = pad + [BOS_index] + Sent2Seq(sent)\n",
    "    decode_y[index] = pad + Sent2Seq(sent) + [EOS_index]\n",
    "    if(len(decode_x[index]) > MAX_SEQ_LEN):\n",
    "        MAX_SEQ_LEN = len(decode_x[index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SZ = len(DIC_word_index) # maybe? need statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1450\n",
      "88\n",
      "MAX_X_LEN:125\n",
      "(1450, 205, 6087)\n",
      "(1450, 205, 1)\n",
      "1450\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "# data1 = pad_sequences(data1, maxlen=MAX_IN_LEN, padding='pre', truncating='pre')\n",
    "\n",
    "#decode_x will be the same len as decode_y\n",
    "print(len(decode_x))\n",
    "print(len(decode_x[0]))\n",
    "decode_x = pad_sequences(decode_x, maxlen=MAX_SEQ_LEN+80, padding='post', truncating='pre')\n",
    "decode_y = pad_sequences(decode_y, maxlen=MAX_SEQ_LEN+80, padding='post', truncating='pre')\n",
    "\n",
    "#print(decode_x)\n",
    "#print(decode_y)\n",
    "print(\"MAX_X_LEN:%d\"%(MAX_SEQ_LEN))\n",
    "# decode_x = decode_x.reshape(decode_x.shape[0],decode_x.shape[1], 1)\n",
    "decode_y = decode_y.reshape(decode_y.shape[0],decode_y.shape[1], 1)\n",
    "decode_x = to_categorical(decode_x, num_classes=VOCAB_SZ)\n",
    "# decode_y = to_categorical(decode_y, num_classes=VOCAB_SZ)\n",
    "print(decode_x.shape)\n",
    "print(decode_y.shape)\n",
    "print(TRAIN_SZ)\n",
    "#input(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "EncoderInput (InputLayer)       (None, 205, 4096)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Encoder (CuDNNGRU)              (None, 205, 128)     1622784     EncoderInput[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "DecoderInput (InputLayer)       (None, 205, 6087)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Concatenate (Concatenate)       (None, 205, 6215)    0           Encoder[0][0]                    \n",
      "                                                                 DecoderInput[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Decoder (CuDNNGRU)              (None, 205, 128)     2436480     Concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, 205, 6087)    785223      Decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 4,844,487\n",
      "Trainable params: 4,844,487\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Using sparse_categorical_crossentropy, we only need to pass integers as input to decoder.\n",
    "EncoderDIM = 128\n",
    "DecoderDIM = 128\n",
    "\n",
    "#decode_x = decode_x[:MAX_SEQ_LEN,:]\n",
    "#decode_y = decode_y[:MAX_SEQ_LEN,:]\n",
    "\n",
    "# Layers\n",
    "t_encoder_input = Input(shape=(80 + MAX_SEQ_LEN, 4096), name=\"EncoderInput\")\n",
    "t_decoder_input = Input(shape=(80 + MAX_SEQ_LEN, VOCAB_SZ), name=\"DecoderInput\")\n",
    "L_encoder = CuDNNGRU(EncoderDIM, return_sequences=True, name='Encoder')\n",
    "L_decoder = CuDNNGRU(DecoderDIM, return_sequences=True, name='Decoder')\n",
    "L_Dense = Dense(VOCAB_SZ, name=\"Dense\", activation='softmax')\n",
    "# L_SM = Softmax(axis=-1, name=\"Softmax\")\n",
    "L_Concat = Concatenate(axis = -1, name='Concatenate')\n",
    "\n",
    "# tensors\n",
    "t_encoder_outputs = L_encoder(t_encoder_input)\n",
    "t_concat_decoder_input = L_Concat([t_encoder_outputs, t_decoder_input] )\n",
    "t_decoder_outputs = L_decoder(t_concat_decoder_input)\n",
    "t_out_probs = TimeDistributed(L_Dense)(t_decoder_outputs)\n",
    "\n",
    "\n",
    "\n",
    "model = Model(inputs=[t_encoder_input, t_decoder_input], outputs=t_out_probs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = [0] * 4096\n",
    "for i,lb in enumerate(open(idfilename)):\n",
    "    #lb contains '\\n', therefore lb[:-1]\n",
    "    lb = lb[:-1]\n",
    "    x = np.load(datadirname + lb + \".npy\")\n",
    "    x = x.tolist()\n",
    "    for j in range(MAX_SEQ_LEN):\n",
    "        x.append(temp)\n",
    "    #print(x)\n",
    "    x = np.array(x)\n",
    "    #print(x.shape)\n",
    "    #input(\"\")\n",
    "    encode_x.append(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1450/1450 [==============================] - 21s 15ms/step - loss: 0.6291 - acc: 0.9417\n",
      "Epoch 2/200\n",
      "1450/1450 [==============================] - 19s 13ms/step - loss: 0.3840 - acc: 0.9433\n",
      "Epoch 3/200\n",
      "1450/1450 [==============================] - 19s 13ms/step - loss: 0.3050 - acc: 0.9535\n",
      "Epoch 4/200\n",
      "1450/1450 [==============================] - 19s 13ms/step - loss: 0.2750 - acc: 0.9604\n",
      "Epoch 5/200\n",
      "1450/1450 [==============================] - 19s 13ms/step - loss: 0.2396 - acc: 0.9631\n",
      "Epoch 6/200\n",
      "1450/1450 [==============================] - 19s 13ms/step - loss: 0.2170 - acc: 0.9643\n",
      "Epoch 7/200\n",
      "1450/1450 [==============================] - 19s 13ms/step - loss: 0.1952 - acc: 0.9658\n",
      "Epoch 8/200\n",
      "1450/1450 [==============================] - 19s 13ms/step - loss: 0.1778 - acc: 0.9670\n",
      "Epoch 9/200\n",
      "1450/1450 [==============================] - 19s 13ms/step - loss: 0.1631 - acc: 0.9684\n",
      "Epoch 10/200\n",
      "1450/1450 [==============================] - 19s 13ms/step - loss: 0.1494 - acc: 0.9696\n",
      "Epoch 11/200\n",
      "1450/1450 [==============================] - 19s 13ms/step - loss: 0.1361 - acc: 0.9712\n",
      "Epoch 12/200\n",
      "1450/1450 [==============================] - 19s 13ms/step - loss: 0.1235 - acc: 0.9728\n",
      "Epoch 13/200\n",
      "1450/1450 [==============================] - 19s 13ms/step - loss: 0.1120 - acc: 0.9747\n",
      "Epoch 14/200\n",
      "1450/1450 [==============================] - 19s 13ms/step - loss: 0.1010 - acc: 0.9765\n",
      "Epoch 15/200\n",
      "1450/1450 [==============================] - 19s 13ms/step - loss: 0.0911 - acc: 0.9787\n",
      "Epoch 16/200\n",
      "1450/1450 [==============================] - 19s 13ms/step - loss: 0.0826 - acc: 0.9808\n",
      "Epoch 17/200\n",
      "1450/1450 [==============================] - 19s 13ms/step - loss: 0.0741 - acc: 0.9828\n",
      "Epoch 18/200\n",
      "1450/1450 [==============================] - 19s 13ms/step - loss: 0.0671 - acc: 0.9845\n",
      "Epoch 19/200\n",
      "  77/1450 [>.............................] - ETA: 18s - loss: 0.0590 - acc: 0.9867"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-98b106597165>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mencode_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_x\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#callbacks=[]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/ML_env/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1637\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1638\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1639\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1641\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/ML_env/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    213\u001b[0m           \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m           \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML_env/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2985\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 2986\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   2987\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2988\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML_env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "optimizer = Adam(lr=1e-3)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "# model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(x=[encode_x, decode_x], y=decode_y, batch_size=1, epochs=200) #callbacks=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_abc = 'modelv2.h5'\n",
    "model.save_weights(MODEL_abc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "EncoderInput (InputLayer)    (None, 205, 4096)         0         \n",
      "_________________________________________________________________\n",
      "Encoder (CuDNNGRU)           (None, 205, 128)          1622784   \n",
      "=================================================================\n",
      "Total params: 1,622,784\n",
      "Trainable params: 1,622,784\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "DecoderInput (InputLayer)       (None, 205, 128)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "DecoderInput2 (InputLayer)      (None, 205, 6087)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Concatenate (Concatenate)       (None, 205, 6215)    0           DecoderInput[0][0]               \n",
      "                                                                 DecoderInput2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "DecoderInput3 (InputLayer)      (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Decoder (CuDNNGRU)              [(None, 205, 128), ( 2436480     Concatenate[0][0]                \n",
      "                                                                 DecoderInput3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 205, 6087)    785223      Decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 3,221,703\n",
      "Trainable params: 3,221,703\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Layers\n",
    "t_encoder_input = Input(shape=(80 + MAX_SEQ_LEN, 4096), name=\"EncoderInput\")\n",
    "t_decoder_hidden_input = Input(shape=(80 + MAX_SEQ_LEN, EncoderDIM), name=\"DecoderInput\")\n",
    "t_decoder_input = Input(shape=(80 + MAX_SEQ_LEN, VOCAB_SZ), name=\"DecoderInput2\")\n",
    "t_decoder_state_input = Input(shape=(DecoderDIM,), name=\"DecoderInput3\")\n",
    "\n",
    "L_encoder = CuDNNGRU(EncoderDIM, return_sequences=True, name='Encoder')\n",
    "L_decoder = CuDNNGRU(DecoderDIM, return_sequences=True, return_state= True, name='Decoder')\n",
    "L_Dense = Dense(VOCAB_SZ, name=\"Dense\", activation='softmax')\n",
    "# L_SM = Softmax(axis=-1, name=\"Softmax\")\n",
    "L_Concat = Concatenate(axis = -1, name='Concatenate')\n",
    "\n",
    "# tensors\n",
    "t_encoder_outputs = L_encoder(t_encoder_input)\n",
    "\n",
    "t_concat_decoder_input = L_Concat([t_decoder_hidden_input, t_decoder_input] )\n",
    "t_decoder_outputs, h_state = L_decoder(t_concat_decoder_input, initial_state = t_decoder_state_input)\n",
    "t_out_probs = TimeDistributed(L_Dense)(t_decoder_outputs)\n",
    "\n",
    "emodel = Model(inputs=t_encoder_input, outputs=t_encoder_outputs)\n",
    "dmodel = Model(inputs = [t_decoder_hidden_input, t_decoder_input, t_decoder_state_input], outputs = [t_out_probs,h_state])\n",
    "\n",
    "#emodel.compile()\n",
    "#dmodel.compile()\n",
    "\n",
    "emodel.summary()\n",
    "dmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "emodel.load_weights(MODEL_abc, by_name = True)\n",
    "dmodel.load_weights(MODEL_abc, by_name = True)\n",
    "\n",
    "#optimizer = Adam(lr=1e-3)\n",
    "\n",
    "#emodel.compile()\n",
    "#odel.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "BOS = '<bos>'\n",
    "EOS = '<eos>'\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = emodel.predict(input_seq)\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = pad_sequences([[ DIC_word_index[BOS] ]], maxlen=81, padding='pre')\n",
    "    \n",
    "    target_seq = pad_sequences(target_seq, maxlen=MAX_SEQ_LEN + 80, padding='post')\n",
    "    \n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = []\n",
    "    t = 0\n",
    "    new_state = np.zeros((1,DecoderDIM));\n",
    "    #print(new_state.shape)\n",
    "    while not stop_condition:\n",
    "        target_seq_cat = to_categorical(target_seq, num_classes=VOCAB_SZ)\n",
    "        #print(new_state.shape)\n",
    "        output_tokens, h = dmodel.predict([ states_value, target_seq_cat, new_state])\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, 80+t, :])\n",
    "#         sampled_token_index = np.argmax(output_tokens[0, 0, :])\n",
    "        sampled_word = DIC_index_word[str(sampled_token_index)]\n",
    "        decoded_sentence.append(sampled_word)\n",
    "        #print(decoded_sentence)\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_word == EOS or len(decoded_sentence) >= MAX_SEQ_LEN):\n",
    "            stop_condition = True\n",
    "        else:\n",
    "            # Update the target sequence (of length 1).\n",
    "            \n",
    "            target_seq[0][80 + t] = sampled_token_index\n",
    "            t += 1\n",
    "            # Update states\n",
    "            new_state = h;\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['drivong', 'triforce', 'drier', 'traveled', 'sweep', 'plaughing', 'seasonings', 'attempting', 'lory', 'gose', 'spilt', 'things', 'been', 'cheesecloth', 'register', 'cheesecloth', 'cheesecloth', 'cheesecloth', 'cheesecloth', 'cheesecloth', 'cheesecloth', 'dogsleds', 'register', 'cheesecloth', 'cheesecloth', 'height', 'sings', 'displaying', 'register', 'cheesecloth', 'cheesecloth', 'feeds', 'cheesecloth', 'worked', 'register', 'register', 'cheesecloth', 'cheesecloth', 'cheesecloth', 'register', 'cheesecloth', 'cheesecloth', 'cheesecloth', 'cheesecloth', 'cheesecloth', 'cheesecloth', 'cheesecloth', 'cheesecloth', 'cheesecloth', 'cheesecloth', 'cheesecloth', 'register', 'cheesecloth', 'register', 'cheesecloth', 'register', 'height', 'register', 'height', 'register', 'sings', 'register', 'sings', 'register', 'sings', 'register', 'cheesecloth', 'cheesecloth', 'cheesecloth', 'cheesecloth', 'cheesecloth', 'cheesecloth', 'register', 'cheesecloth', 'register', 'cheesecloth', 'register', 'height', 'register', 'height', 'cheesecloth', 'height', 'cheesecloth', 'cheesecloth', 'cheesecloth', 'cheesecloth', 'cheesecloth', 'cheesecloth', 'cheesecloth', 'cheesecloth', 'cheesecloth', 'cheesecloth', 'cheesecloth', 'cheesecloth', 'cheesecloth', 'cheesecloth', 'height', 'register', 'height', 'register', 'height', 'cheesecloth', 'height', 'cheesecloth', 'cheesecloth', 'cheesecloth', 'cheesecloth', 'cheesecloth', 'cheesecloth', 'cheesecloth', 'cheesecloth', 'cheesecloth', 'cheesecloth', 'cheesecloth', 'cheesecloth', 'cheesecloth', 'cheesecloth', 'height', 'cheesecloth', 'height', 'cheesecloth', 'height', 'cheesecloth', 'height', 'cheesecloth']\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "index = 3\n",
    "test = encode_x[index].reshape(1, encode_x[index].shape[0],encode_x[index].shape[1])\n",
    "ret = decode_sequence(test)\n",
    "print(ret)\n",
    "print(decode_x[index])\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
