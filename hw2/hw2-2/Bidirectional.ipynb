{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] =\"-1\"\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# import torchvision\n",
    "\n",
    "#from keras.preprocessing.sequence import pad_sequences\n",
    "#from keras.utils import to_categorical\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import json\n",
    "\n",
    "from torch.utils.data.dataloader import default_collate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "DIC_word_index = json.load(open(\"vocab.json\", \"r\", encoding='utf-8'))\n",
    "DIC_index_word = {index:word for word, index in DIC_word_index.items()}\n",
    "word_vectors = np.load(\"wv_matrix100d.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'別'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DIC_index_word[97]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2sent(seq):\n",
    "    return [DIC_index_word[i] for i in seq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_words(ys):       \n",
    "    tokens = []\n",
    "    #print(ys)\n",
    "    #input(\"\")\n",
    "    for catagorical_word in ys:\n",
    "        index = np.argmax(catagorical_word.cpu().detach().numpy())\n",
    "        #print(index)\n",
    "        if index in DIC_index_word:\n",
    "            tokens.append(DIC_index_word[index])\n",
    "        else:\n",
    "            tokens.append('<unk>');\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _run_iter(batch, training, model, loss_function):\n",
    "    with torch.no_grad():\n",
    "        e_x = batch['encoder_x'].long().to(device)\n",
    "        d_x = batch['decoder_x'].long().to(device)\n",
    "    output = model.forward(e_x, d_x, 0.5)\n",
    "    #print(output.shape)\n",
    "    #print(batch['decoder_y'].shape)\n",
    "    #input(\"\")\n",
    "    #print(output)\n",
    "    #input(\"\")\n",
    "    loss = loss_function(output.view(-1, len(word_vectors)), batch['decoder_y'].view(-1).long().to(device))\n",
    "    return output, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _run_epoch(dataloader, training, model, optimizer, loss_function):\n",
    "    model.train(training)\n",
    "    if training:\n",
    "        iter_in_epoch = min(len(dataloader), 1000000)\n",
    "        description = 'train'\n",
    "    else:\n",
    "        iter_in_epoch = len(dataloader)\n",
    "        description = 'test'\n",
    "    grad_accumulate_steps = 1\n",
    "    trange = tqdm(enumerate(dataloader), total=iter_in_epoch, desc=description)\n",
    "    loss = 0\n",
    "    for i, batch in trange:   \n",
    "        if training and i >= iter_in_epoch:\n",
    "            break\n",
    "\n",
    "        if training:\n",
    "            #print(\"batch:{}\".format(batch))\n",
    "            #print(batch['context'].dtype)\n",
    "            optimizer.zero_grad()\n",
    "            output, batch_loss = _run_iter(batch, training, model, loss_function)            \n",
    "            \n",
    "            batch_loss /= grad_accumulate_steps\n",
    "            \n",
    "            if i % grad_accumulate_steps == 0:\n",
    "                optimizer.zero_grad()\n",
    "            \n",
    "            batch_loss.backward()\n",
    "            \n",
    "            print(\"loss: {}\".format(loss/(i+1)), end='\\r')\n",
    "\n",
    "            if (i + 1) % grad_accumulate_steps == 0:\n",
    "                optimizer.step()\n",
    "            if((i+1) % 1500 == 0):\n",
    "                print([DIC_index_word[i.item()] for i in batch['decoder_y'][0].cpu().detach()])\n",
    "                print(to_words(output[0]))\n",
    "                print(batch_loss)\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                output, batch_loss = _run_iter(batch, training, model, loss_function)\n",
    "                if((i+1) % 1500 == 0):\n",
    "                    print([DIC_index_word[i.item()] for i in batch['decoder_y'][0].cpu().detach()])\n",
    "                    print(to_words(output[0]))\n",
    "                \n",
    "        loss += batch_loss.item()\n",
    "\n",
    "    loss /= iter_in_epoch\n",
    "    print('loss=%f\\n' % loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_post_zero(a, length):\n",
    "    ret = []\n",
    "    for _list in a:\n",
    "        if(len(_list) < length):\n",
    "            for ct in range(len(_list),length,1):\n",
    "                _list.append(DIC_word_index[\"<pad>\"])\n",
    "        if(len(_list) > length):\n",
    "            _list = _list[:length]\n",
    "            \n",
    "        ret.append(_list)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_categorical(y, num_classes=None, dtype='float32'):\n",
    "    \"\"\"Converts a class vector (integers) to binary class matrix.\n",
    "    E.g. for use with categorical_crossentropy.\n",
    "    # Arguments\n",
    "        y: class vector to be converted into a matrix\n",
    "            (integers from 0 to num_classes).\n",
    "        num_classes: total number of classes.\n",
    "        dtype: The data type expected by the input, as a string\n",
    "            (`float32`, `float64`, `int32`...)\n",
    "    # Returns\n",
    "        A binary matrix representation of the input. The classes axis\n",
    "        is placed last.\n",
    "    # Example\n",
    "    ```python\n",
    "    # Consider an array of 5 labels out of a set of 3 classes {0, 1, 2}:\n",
    "    > labels\n",
    "    array([0, 2, 1, 2, 0])\n",
    "    # `to_categorical` converts this into a matrix with as many\n",
    "    # columns as there are classes. The number of rows\n",
    "    # stays the same.\n",
    "    > to_categorical(labels)\n",
    "    array([[ 1.,  0.,  0.],\n",
    "           [ 0.,  0.,  1.],\n",
    "           [ 0.,  1.,  0.],\n",
    "           [ 0.,  0.,  1.],\n",
    "           [ 1.,  0.,  0.]], dtype=float32)\n",
    "    ```\n",
    "    \"\"\"\n",
    "\n",
    "    y = np.array(y, dtype='int')\n",
    "    input_shape = y.shape\n",
    "    if input_shape and input_shape[-1] == 1 and len(input_shape) > 1:\n",
    "        input_shape = tuple(input_shape[:-1])\n",
    "    y = y.ravel()\n",
    "    if not num_classes:\n",
    "        num_classes = np.max(y) + 1\n",
    "    n = y.shape[0]\n",
    "    categorical = np.zeros((n, num_classes), dtype=dtype)\n",
    "    categorical[np.arange(n), y] = 1\n",
    "    output_shape = input_shape + (num_classes,)\n",
    "    categorical = np.reshape(categorical, output_shape)\n",
    "    return categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_collate(datas):\n",
    "    batch = {}\n",
    "    # collate lists\n",
    "    batch['decoder_x'] = torch.tensor([data['decoder_x'] for data in datas])\n",
    "    batch['decoder_y'] = torch.tensor([data['decoder_y'] for data in datas])\n",
    "    batch['encoder_x'] = torch.tensor([data['encoder_x'] for data in datas])\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_len = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_x = []\n",
    "with open('sel_conversation/question.txt', 'r') as f:\n",
    "    for l in f:\n",
    "        l = l.split()\n",
    "        tmp = []\n",
    "        for word in l:\n",
    "            try:\n",
    "                index = DIC_word_index[word]\n",
    "            except KeyError:\n",
    "                index = DIC_word_index['<unk>']\n",
    "            tmp.append(index)\n",
    "        encode_x.append([DIC_word_index['<bos>']] + tmp + [DIC_word_index['<eos>']])        \n",
    "encode_x = pad_post_zero(encode_x, sent_len)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<bos>', '導致', '四個', '州', '停電', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>']\n"
     ]
    }
   ],
   "source": [
    "print(seq2sent(encode_x[73]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_x = []\n",
    "decode_y = []\n",
    "with open('sel_conversation/answer.txt', 'r') as f:\n",
    "    for l in f:\n",
    "        l = l.split()\n",
    "        tmp = []\n",
    "        for word in l:\n",
    "            try:\n",
    "                index = DIC_word_index[word]\n",
    "            except KeyError:\n",
    "                index = DIC_word_index['<unk>']\n",
    "            tmp.append(index)\n",
    "        decode_x.append([DIC_word_index['<bos>']] + tmp)    \n",
    "        decode_y.append( tmp + [DIC_word_index['<eos>']])\n",
    "    decode_x = pad_post_zero(decode_x, sent_len)\n",
    "    decode_y = pad_post_zero(decode_y, sent_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<bos>', '在', '最新', '民調', '中', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "['在', '最新', '民調', '中', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n"
     ]
    }
   ],
   "source": [
    "print(seq2sent(decode_x[68]))\n",
    "print(seq2sent(decode_y[68]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = []\n",
    "for a,b,c in zip(decode_x, decode_y , encode_x):\n",
    "    data = {}\n",
    "\n",
    "    data['decoder_x'] = a\n",
    "    data['decoder_y'] = b;\n",
    "    data['encoder_x'] = c;\n",
    "    \n",
    "    datas.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRNN(torch.nn.Module):\n",
    "    def __init__(self, latent_dim, seq_length, embed_dim, word_vectors):\n",
    "        super(SimpleRNN, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = latent_dim        \n",
    "        self.seq_length = seq_length\n",
    "        self.embed_dim = embed_dim\n",
    "        \n",
    "#         self.embedding = torch.nn.Embedding(len(word_vectors), embed_dim)\n",
    "#         self.embedding.load_state_dict({'weight': word_vectors})\n",
    "#         self.embedding.weight.requires_grad = False\n",
    "        self.embedding = torch.nn.Embedding.from_pretrained(torch.from_numpy(word_vectors),freeze=True)\n",
    "#        self.embedding = torch.nn.Embedding(len(word_vectors), embed_dim)\n",
    "    \n",
    "        self.GRU1 = torch.nn.GRU(self.embed_dim, latent_dim,  num_layers=1, batch_first = True)\n",
    "        self.GRU2 = torch.nn.GRU(self.embed_dim, latent_dim,  num_layers=1, batch_first = True)\n",
    "        \n",
    "        self.Projection_layer = torch.nn.Sequential(\n",
    "            torch.nn.Linear(latent_dim, len(word_vectors)),\n",
    "        )\n",
    "    def encoder_GRU(self, e_x):\n",
    "        e_y, hiddens = self.GRU1(e_x)\n",
    "        \n",
    "        return e_y, hiddens\n",
    "    \n",
    "    def decoder_GRU(self, d_x, hiddens):\n",
    "        d_y, hiddens2 = self.GRU2(d_x, hiddens)\n",
    "        return d_y, hiddens2\n",
    "    \n",
    "    def forward(self, e_x, d_x):\n",
    "        e_x = self.embedding(e_x).float()\n",
    "        \n",
    "        d_x = self.embedding(d_x).float()\n",
    "        \n",
    "        \n",
    "        e_y, hiddens = self.encoder_GRU(e_x)\n",
    "        \n",
    "        first = True\n",
    "        \n",
    "#         for word in d_x.transpose(1,0):\n",
    "#             word = word.view(word.shape[0], 1, -1)\n",
    "#             d_y, hiddens = self.decoder_GRU(word, hiddens)\n",
    "            \n",
    "# #             print(d_y.shape)\n",
    "#             if(first):\n",
    "#                 first = False;\n",
    "#                 last_layer_input = d_y\n",
    "#             else:\n",
    "#                 last_layer_input = torch.cat((last_layer_input, d_y), 1)\n",
    "#         #print(last_layer_input.shape)\n",
    "#         output = self.Projection_layer(last_layer_input)\n",
    "        for word in d_x.transpose(1,0):\n",
    "            word = word.view(word.shape[0], 1, -1)\n",
    "            d_y, hiddens = self.decoder_GRU(word, hiddens)\n",
    "            \n",
    "            if(first):\n",
    "                first = False;\n",
    "                last_layer_input = self.Projection_layer(d_y)\n",
    "            else:\n",
    "                last_layer_input = torch.cat((last_layer_input, self.Projection_layer(d_y)), 1)\n",
    "\n",
    "        output = last_layer_input\n",
    "        #print(output)\n",
    "        \n",
    "        return output\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiAttModel(torch.nn.Module):\n",
    "    def __init__(self, latent_dim, seq_length, embed_dim, word_vectors):\n",
    "        super(BiAttModel, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = latent_dim        \n",
    "        self.seq_length = seq_length\n",
    "        self.embed_dim = embed_dim\n",
    "        \n",
    "#         self.embedding = torch.nn.Embedding(len(word_vectors), embed_dim)\n",
    "#         self.embedding.load_state_dict({'weight': word_vectors})\n",
    "#         self.embedding.weight.requires_grad = False\n",
    "        self.embedding = torch.nn.Embedding.from_pretrained(torch.from_numpy(word_vectors), freeze=True)\n",
    "#        self.embedding = torch.nn.Embedding(len(word_vectors), embed_dim)\n",
    "    \n",
    "        self.soft = torch.nn.Softmax(-2)\n",
    "        \n",
    "        self.RNN1 = torch.nn.LSTM(self.embed_dim, latent_dim,  num_layers=2, bidirectional = True, batch_first = True)\n",
    "        self.RNN2 = torch.nn.LSTM(self.embed_dim, latent_dim * 2,  num_layers=2, batch_first = True)\n",
    "        \n",
    "        self.Projection_layer = torch.nn.Sequential(\n",
    "            torch.nn.Linear(4 * latent_dim, len(word_vectors)),\n",
    "        )\n",
    "        \n",
    "        self.trainable_W = torch.nn.Sequential(\n",
    "            torch.nn.Linear(2 * latent_dim , 2 * latent_dim),\n",
    "            torch.nn.Sigmoid(),\n",
    "            torch.nn.Dropout(p=0.2),\n",
    "        )\n",
    "    def encoder_RNN(self, e_x):\n",
    "        e_y, hiddens = self.RNN1(e_x)\n",
    "        \n",
    "        return e_y, hiddens\n",
    "    \n",
    "    def decoder_RNN(self, d_x, hiddens):\n",
    "        d_y, hiddens2 = self.RNN2(d_x, hiddens)\n",
    "        return d_y, hiddens2\n",
    "    \n",
    "    def forward(self, e_x, d_x, probs):\n",
    "        e_x = self.embedding(e_x).float()\n",
    "        \n",
    "        d_x = self.embedding(d_x).float()\n",
    "\n",
    "        #print(sent.shape) torch.Size([2, 15, 6087])\n",
    "\n",
    "        e_output, hiddens = self.encoder_RNN(e_x)\n",
    "        \n",
    "        #attention\n",
    "        uW = self.trainable_W(e_output)\n",
    "        #hiddens = [hiddens[0].view(int(hiddens[0].shape[0]/2), hiddens[0].shape[1], hiddens[0].shape[2]*2), hiddens[1].view(int(hiddens[1].shape[0]/2), hiddens[1].shape[1], hiddens[1].shape[2]*2)]\n",
    "\n",
    "        h = hiddens[0].transpose(1,0).contiguous()\n",
    "        h = h.view(-1, 2, hiddens[0].shape[-1]*2)\n",
    "        h = h.transpose(1,0).contiguous()\n",
    "        \n",
    "        c = hiddens[1].transpose(1,0).contiguous()\n",
    "        c = c.view(-1, 2, hiddens[1].shape[-1]*2)\n",
    "        c = c.transpose(1,0).contiguous()\n",
    "        \n",
    "\n",
    "        hiddens = [h, c]\n",
    "        \n",
    "        probs = 0.5;\n",
    "        #linear_decay_rate = 0.1;\n",
    "        \n",
    "        first = True\n",
    "        pre = None\n",
    "        for word in d_x.transpose(1,0):\n",
    "            #print(word.shape) torch.Size([2, 6087])\n",
    "            word = torch.unsqueeze(word , 1)\n",
    "            #torch.Size([128, 1, 100])\n",
    "            \n",
    "#             #sample a word here\n",
    "#             if (not first) and np.random.rand() < probs:\n",
    "#                 wordprob = self.Projection_layer(pre)\n",
    "#                 #print(wordprob.shape)torch.Size([128, 1, 46801])\n",
    "#                 ans_indices = torch.argmax(wordprob, dim=-1, keepdim=False)\n",
    "#                 word = self.embedding(ans_indices).float()\n",
    "#                 #torch.Size([128, 1, 100])\n",
    "            \n",
    "            #or randomize for each data in batch\n",
    "            #probs -= linear_decay_rate\n",
    "            if not first:\n",
    "                useTeacher = (torch.rand(word.shape[0]) < probs).float().view(-1, 1, 1).to(device)\n",
    "                useSample = 1.0 - useTeacher\n",
    "                \n",
    "                #get previous output\n",
    "                wordprob = self.Projection_layer(pre)\n",
    "                ans_indices = torch.argmax(wordprob, dim=-1, keepdim=False)\n",
    "                preword = self.embedding(ans_indices).float()\n",
    "                \n",
    "                #mixture\n",
    "                word = useTeacher*word + useSample*preword\n",
    "                \n",
    "                \n",
    "                \n",
    "            \n",
    "\n",
    "            #print(word.shape)\n",
    "            #one for each word, therefore d_output = d_state\n",
    "            d_output, hiddens = self.decoder_RNN(word, hiddens)\n",
    "            uWv = torch.matmul(uW, d_output.transpose(2,1))\n",
    "            #print(uWv.shape) torch.Size([2, 80, 1])\n",
    "            alpha = self.soft(uWv)\n",
    "            #print(uWv)\n",
    "            #print(alpha)\n",
    "            #input(\"\")\n",
    "            new_context = e_output.transpose(2,1) @ alpha;\n",
    "            #print(e_output.shape) torch.Size([2, 80, 256])\n",
    "            #print(alpha.shape) torch.Size([2, 80, 1])\n",
    "            \n",
    "            #print(d_output.shape) torch.Size([2, 1, 256])\n",
    "            #print(new_context.shape) torch.Size([2, 256, 1])          \n",
    "            pre = torch.cat((d_output, new_context.transpose(2,1)), 2)\n",
    "            if(first):\n",
    "                first = 0;\n",
    "                last_layer_input = pre\n",
    "            else:\n",
    "                last_layer_input = torch.cat((last_layer_input, pre), 1)\n",
    "            #print(last_layer_input.shape) #torch.Size([2, 1, 512])\n",
    "            \n",
    "        logits = self.Projection_layer(last_layer_input)\n",
    "\n",
    "        #logits = torch.stack(logits, 1)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46801, 100)\n"
     ]
    }
   ],
   "source": [
    "#hyperparameters\n",
    "lr = 5e-3  # learning rate\n",
    "batch_size = 512\n",
    "latent_dim = 512\n",
    "iter_in_epoch = 500\n",
    "embed_dim = word_vectors.shape[1]\n",
    "print(word_vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4da34d13e8094c83ac9d89eb3f594593",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train', max=1720, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['你', '聽到', '了', '嗎', '?', '即使', '反對', '。', '<eos>', '<pad>']\n",
      "['我', '知道', '我', '?', '<eos>', '<eos>', '我', '是', '<eos>', '<eos>']\n",
      "tensor(5.1348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss: 5.4260387686795975\n",
      "loss=5.429006\n",
      "\n",
      "training 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f183c17dc9941e18987820dea4cd8ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train', max=1720, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 5.0899592870953445\r"
     ]
    }
   ],
   "source": [
    "model = BiAttModel(latent_dim, sent_len, embed_dim, word_vectors)\n",
    "#saved_model = torch.load(\"models/Model103\")\n",
    "#model.load_state_dict(saved_model['model'])\n",
    "\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=lr)\n",
    "#optimizer.load_state_dict(saved_model['optimizer'])\n",
    "loss_function = torch.nn.CrossEntropyLoss(ignore_index=DIC_word_index['<pad>'])\n",
    "\n",
    "epoch = 0\n",
    "#epoch = saved_model['epoch']\n",
    "max_epochs = 150  # how many epochs to train for\n",
    "while epoch < max_epochs:\n",
    "    # train and evaluate train score\n",
    "    print('training %i' % epoch)\n",
    "\n",
    "    # train epoch\n",
    "    dataloader = torch.utils.data.DataLoader(datas, batch_size = batch_size, shuffle = True, collate_fn = my_collate)\n",
    "    log_train = _run_epoch(dataloader, True, model, optimizer, loss_function)\n",
    "\n",
    "    # test epoch\n",
    "    \"\"\"\n",
    "    print('evaluating %i' % epoch)\n",
    "    dataloader = torch.utils.data.DataLoader(valid_datas, batch_size = batch_size, collate_fn=my_collate)\n",
    "    log_valid = _run_epoch(dataloader, False, model, optimizer, loss_function)\n",
    "    \"\"\"\n",
    "    \n",
    "    epoch += 1\n",
    "    if epoch % 1 == 0:\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict()\n",
    "        }, \"./models/Model\" + str(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'model': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict()\n",
    "        }, \"./models/Model\" + str(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #model = SimpleRNN(latent_dim, sent_len, embed_dim, word_vectors)\n",
    "# model = AttModel(latent_dim, sent_len, embed_dim, word_vectors)\n",
    "\n",
    "# model = model.to(device)\n",
    "# optimizer = torch.optim.Adam(model.parameters(),lr=lr)\n",
    "# loss_function = torch.nn.CrossEntropyLoss(ignore_index=DIC_word_index['<pad>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# epoch = 0;\n",
    "# max_epochs = 100  # how many epochs to train for\n",
    "# while epoch < max_epochs:\n",
    "#     # train and evaluate train score\n",
    "#     print('training %i' % epoch)\n",
    "\n",
    "#     # train epoch\n",
    "#     dataloader = torch.utils.data.DataLoader(datas, batch_size = batch_size, shuffle = True, collate_fn = my_collate)\n",
    "#     log_train = _run_epoch(dataloader, True, model, optimizer, loss_function)\n",
    "\n",
    "#     # test epoch\n",
    "#     \"\"\"\n",
    "#     print('evaluating %i' % epoch)\n",
    "#     dataloader = torch.utils.data.DataLoader(valid_datas, batch_size = batch_size, collate_fn=my_collate)\n",
    "#     log_valid = _run_epoch(dataloader, False, model, optimizer, loss_function)\n",
    "#     \"\"\"\n",
    "    \n",
    "#     epoch += 1\n",
    "#     torch.save({\n",
    "#         'epoch': epoch + 1,\n",
    "#         'model': model.state_dict(),\n",
    "#         'optimizer': optimizer.state_dict()\n",
    "#     }, \"./models/Model\" + str(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(DIC_word_index['<pad>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
