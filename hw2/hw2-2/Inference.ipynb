{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] =\"-1\"\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# import torchvision\n",
    "\n",
    "#from keras.preprocessing.sequence import pad_sequences\n",
    "#from keras.utils import to_categorical\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import json\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "\n",
    "from torch.utils.data.dataloader import default_collate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "DIC_word_index = json.load(open(\"vocab.json\", \"r\", encoding='utf-8'))\n",
    "DIC_index_word = {index:word for word, index in DIC_word_index.items()}\n",
    "word_vectors = np.load(\"wv_matrix100d.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_len = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceAttModel(torch.nn.Module):\n",
    "    def __init__(self, latent_dim, seq_length, embed_dim, word_vectors):\n",
    "        super(AttModel, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = latent_dim        \n",
    "        self.seq_length = seq_length\n",
    "        self.embed_dim = embed_dim\n",
    "        \n",
    "#         self.embedding = torch.nn.Embedding(len(word_vectors), embed_dim)\n",
    "#         self.embedding.load_state_dict({'weight': word_vectors})\n",
    "#         self.embedding.weight.requires_grad = False\n",
    "        self.embedding = torch.nn.Embedding.from_pretrained(torch.from_numpy(word_vectors), freeze=True)\n",
    "#        self.embedding = torch.nn.Embedding(len(word_vectors), embed_dim)\n",
    "    \n",
    "        self.soft = torch.nn.Softmax(-2)\n",
    "        \n",
    "        self.RNN1 = torch.nn.LSTM(self.embed_dim, latent_dim,  num_layers=2, batch_first = True)\n",
    "        self.RNN2 = torch.nn.LSTM(self.embed_dim, latent_dim,  num_layers=2, batch_first = True)\n",
    "        \n",
    "        self.Projection_layer = torch.nn.Sequential(\n",
    "            torch.nn.Linear(2 * latent_dim, len(word_vectors)),\n",
    "        )\n",
    "        \n",
    "        self.trainable_W = torch.nn.Sequential(\n",
    "            torch.nn.Linear(latent_dim ,  latent_dim),\n",
    "            torch.nn.Sigmoid(),\n",
    "            torch.nn.Dropout(p=0.2),\n",
    "        )\n",
    "    def encoder_RNN(self, e_x):\n",
    "        e_y, hiddens = self.RNN1(e_x)\n",
    "        \n",
    "        return e_y, hiddens\n",
    "    \n",
    "    def decoder_RNN(self, d_x, hiddens):\n",
    "        d_y, hiddens2 = self.RNN2(d_x, hiddens)\n",
    "        return d_y, hiddens2\n",
    "    \n",
    "    def forward(self, e_x, ):\n",
    "        e_x = self.embedding(e_x).float()\n",
    "        batch_size = e_x.shape[0]\n",
    "        if(batch_size != 1):\n",
    "            print(\"Batch size > 1 is not available now. Batch size please give 1.\")\n",
    "            return\n",
    "        #print(sent.shape) torch.Size([2, 15, 6087])\n",
    "\n",
    "        e_output, hiddens = self.encoder_RNN(e_x)\n",
    "        \n",
    "        #attention\n",
    "        uW = self.trainable_W(e_output)\n",
    "        \n",
    "        first = True\n",
    "        first_index = DIC_word_index['<bos>']\n",
    "        first_input = torch.tensor([[first_index] * batch_size])\n",
    "        first_input = first.view(batch_size, 1, 1)\n",
    "        ans_seq = []\n",
    "        for i in range(len(self.seq_length)):\n",
    "            #print(word.shape) torch.Size([2, 6087])\n",
    "            if(first):\n",
    "                word = first_input;\n",
    "                first = False\n",
    "            \n",
    "            word = self.embedding(word.view(batch_size, 1, -1));\n",
    "            #print(word.shape)\n",
    "            #one for each word, therefore d_output = d_state\n",
    "            d_output, hiddens = self.decoder_RNN(word, hiddens)\n",
    "            uWv = torch.matmul(uW, d_output.transpose(2,1))\n",
    "            #print(uWv.shape) torch.Size([2, 80, 1])\n",
    "            alpha = self.soft(uWv)\n",
    "            #print(uWv)\n",
    "            #print(alpha)\n",
    "            #input(\"\")\n",
    "            new_context = e_output.transpose(2,1) @ alpha;\n",
    "            #print(e_output.shape) torch.Size([2, 80, 256])\n",
    "            #print(alpha.shape) torch.Size([2, 80, 1])\n",
    "            \n",
    "            #print(d_output.shape) torch.Size([2, 1, 256])\n",
    "            #print(new_context.shape) torch.Size([2, 256, 1])          \n",
    "            pre = torch.cat((d_output, new_context.transpose(2,1)), 2)\n",
    "            ans_logits = self.Projection_layer(pre)\n",
    "            ans_index = np.argmax(ans_logits.cpu().detach().numpy())\n",
    "            ans = DIC_index_word(ans_index)\n",
    "            ans_seq.append(ans)\n",
    "            word = torch.tensor([ans_index])\n",
    "\n",
    "        #logits = torch.stack(logits, 1)\n",
    "        return ans_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
