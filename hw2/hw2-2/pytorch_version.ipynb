{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] =\"-1\"\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# import torchvision\n",
    "\n",
    "#from keras.preprocessing.sequence import pad_sequences\n",
    "#from keras.utils import to_categorical\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import json\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "\n",
    "from torch.utils.data.dataloader import default_collate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "DIC_word_index = json.load(open(\"vocab.json\", \"r\", encoding='utf-8'))\n",
    "DIC_index_word = {index:word for word, index in DIC_word_index.items()}\n",
    "word_vectors = np.load(\"wv_matrix100d.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'別'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DIC_index_word[97]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2sent(seq):\n",
    "    return [DIC_index_word[i] for i in seq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_words(ys):       \n",
    "    tokens = []\n",
    "    #print(ys)\n",
    "    #input(\"\")\n",
    "    for catagorical_word in ys:\n",
    "        index = np.argmax(catagorical_word.cpu().detach().numpy())\n",
    "        #print(index)\n",
    "        if index in DIC_index_word:\n",
    "            tokens.append(DIC_index_word[index])\n",
    "        else:\n",
    "            tokens.append('<unk>');\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _run_iter(batch, training, model, loss_function):\n",
    "    with torch.no_grad():\n",
    "        e_x = batch['encoder_x'].long().to(device)\n",
    "        d_x = batch['decoder_x'].long().to(device)\n",
    "    output = model.forward(e_x, d_x, 0.5)\n",
    "    #print(output.shape)\n",
    "    #print(batch['decoder_y'].shape)\n",
    "    #input(\"\")\n",
    "    #print(output)\n",
    "    #input(\"\")\n",
    "    loss = loss_function(output.view(-1, len(word_vectors)), batch['decoder_y'].view(-1).long().to(device))\n",
    "    return output, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _run_epoch(dataloader, training, model, optimizer, loss_function):\n",
    "    model.train(training)\n",
    "    if training:\n",
    "        iter_in_epoch = min(len(dataloader), 1000000)\n",
    "        description = 'train'\n",
    "    else:\n",
    "        iter_in_epoch = len(dataloader)\n",
    "        description = 'test'\n",
    "    grad_accumulate_steps = 1\n",
    "    trange = tqdm(enumerate(dataloader), total=iter_in_epoch, desc=description)\n",
    "    loss = 0\n",
    "    for i, batch in trange:   \n",
    "        if training and i >= iter_in_epoch:\n",
    "            break\n",
    "\n",
    "        if training:\n",
    "            #print(\"batch:{}\".format(batch))\n",
    "            #print(batch['context'].dtype)\n",
    "            optimizer.zero_grad()\n",
    "            output, batch_loss = _run_iter(batch, training, model, loss_function)            \n",
    "            \n",
    "            batch_loss /= grad_accumulate_steps\n",
    "            \n",
    "            if i % grad_accumulate_steps == 0:\n",
    "                optimizer.zero_grad()\n",
    "            \n",
    "            batch_loss.backward()\n",
    "            \n",
    "            print(\"loss: {}\".format(loss/(i+1)), end='\\r')\n",
    "\n",
    "            if (i + 1) % grad_accumulate_steps == 0:\n",
    "                optimizer.step()\n",
    "            if((i+1) % 1500 == 0):\n",
    "                print([DIC_index_word[i.item()] for i in batch['decoder_y'][0].cpu().detach()])\n",
    "                print(to_words(output[0]))\n",
    "                print(batch_loss)\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                output, batch_loss = _run_iter(batch, training, model, loss_function)\n",
    "                if((i+1) % 1500 == 0):\n",
    "                    print([DIC_index_word[i.item()] for i in batch['decoder_y'][0].cpu().detach()])\n",
    "                    print(to_words(output[0]))\n",
    "                \n",
    "        loss += batch_loss.item()\n",
    "\n",
    "    loss /= iter_in_epoch\n",
    "    print('loss=%f\\n' % loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_post_zero(a, length):\n",
    "    ret = []\n",
    "    for _list in a:\n",
    "        if(len(_list) < length):\n",
    "            for ct in range(len(_list),length,1):\n",
    "                _list.append(DIC_word_index[\"<pad>\"])\n",
    "        if(len(_list) > length):\n",
    "            _list = _list[:length]\n",
    "            \n",
    "        ret.append(_list)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_categorical(y, num_classes=None, dtype='float32'):\n",
    "    \"\"\"Converts a class vector (integers) to binary class matrix.\n",
    "    E.g. for use with categorical_crossentropy.\n",
    "    # Arguments\n",
    "        y: class vector to be converted into a matrix\n",
    "            (integers from 0 to num_classes).\n",
    "        num_classes: total number of classes.\n",
    "        dtype: The data type expected by the input, as a string\n",
    "            (`float32`, `float64`, `int32`...)\n",
    "    # Returns\n",
    "        A binary matrix representation of the input. The classes axis\n",
    "        is placed last.\n",
    "    # Example\n",
    "    ```python\n",
    "    # Consider an array of 5 labels out of a set of 3 classes {0, 1, 2}:\n",
    "    > labels\n",
    "    array([0, 2, 1, 2, 0])\n",
    "    # `to_categorical` converts this into a matrix with as many\n",
    "    # columns as there are classes. The number of rows\n",
    "    # stays the same.\n",
    "    > to_categorical(labels)\n",
    "    array([[ 1.,  0.,  0.],\n",
    "           [ 0.,  0.,  1.],\n",
    "           [ 0.,  1.,  0.],\n",
    "           [ 0.,  0.,  1.],\n",
    "           [ 1.,  0.,  0.]], dtype=float32)\n",
    "    ```\n",
    "    \"\"\"\n",
    "\n",
    "    y = np.array(y, dtype='int')\n",
    "    input_shape = y.shape\n",
    "    if input_shape and input_shape[-1] == 1 and len(input_shape) > 1:\n",
    "        input_shape = tuple(input_shape[:-1])\n",
    "    y = y.ravel()\n",
    "    if not num_classes:\n",
    "        num_classes = np.max(y) + 1\n",
    "    n = y.shape[0]\n",
    "    categorical = np.zeros((n, num_classes), dtype=dtype)\n",
    "    categorical[np.arange(n), y] = 1\n",
    "    output_shape = input_shape + (num_classes,)\n",
    "    categorical = np.reshape(categorical, output_shape)\n",
    "    return categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_collate(datas):\n",
    "    batch = {}\n",
    "    # collate lists\n",
    "    batch['decoder_x'] = torch.tensor([data['decoder_x'] for data in datas])\n",
    "    batch['decoder_y'] = torch.tensor([data['decoder_y'] for data in datas])\n",
    "    batch['encoder_x'] = torch.tensor([data['encoder_x'] for data in datas])\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_len = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_x = []\n",
    "with open('sel_conversation/question.txt', 'r') as f:\n",
    "    for l in f:\n",
    "        l = l.split()\n",
    "        tmp = []\n",
    "        for word in l:\n",
    "            try:\n",
    "                index = DIC_word_index[word]\n",
    "            except KeyError:\n",
    "                index = DIC_word_index['<unk>']\n",
    "            tmp.append(index)\n",
    "        encode_x.append([DIC_word_index['<bos>']] + tmp + [DIC_word_index['<eos>']])        \n",
    "encode_x = pad_post_zero(encode_x, sent_len)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<bos>', '導致', '四個', '州', '停電', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>']\n"
     ]
    }
   ],
   "source": [
    "print(seq2sent(encode_x[73]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_x = []\n",
    "decode_y = []\n",
    "with open('sel_conversation/answer.txt', 'r') as f:\n",
    "    for l in f:\n",
    "        l = l.split()\n",
    "        tmp = []\n",
    "        for word in l:\n",
    "            try:\n",
    "                index = DIC_word_index[word]\n",
    "            except KeyError:\n",
    "                index = DIC_word_index['<unk>']\n",
    "            tmp.append(index)\n",
    "        decode_x.append([DIC_word_index['<bos>']] + tmp)    \n",
    "        decode_y.append( tmp + [DIC_word_index['<eos>']])\n",
    "    decode_x = pad_post_zero(decode_x, sent_len)\n",
    "    decode_y = pad_post_zero(decode_y, sent_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<bos>', '在', '最新', '民調', '中', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "['在', '最新', '民調', '中', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n"
     ]
    }
   ],
   "source": [
    "print(seq2sent(decode_x[68]))\n",
    "print(seq2sent(decode_y[68]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = []\n",
    "for a,b,c in zip(decode_x, decode_y , encode_x):\n",
    "    data = {}\n",
    "\n",
    "    data['decoder_x'] = a\n",
    "    data['decoder_y'] = b;\n",
    "    data['encoder_x'] = c;\n",
    "    \n",
    "    datas.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRNN(torch.nn.Module):\n",
    "    def __init__(self, latent_dim, seq_length, embed_dim, word_vectors):\n",
    "        super(SimpleRNN, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = latent_dim        \n",
    "        self.seq_length = seq_length\n",
    "        self.embed_dim = embed_dim\n",
    "        \n",
    "#         self.embedding = torch.nn.Embedding(len(word_vectors), embed_dim)\n",
    "#         self.embedding.load_state_dict({'weight': word_vectors})\n",
    "#         self.embedding.weight.requires_grad = False\n",
    "        self.embedding = torch.nn.Embedding.from_pretrained(torch.from_numpy(word_vectors),freeze=True)\n",
    "#        self.embedding = torch.nn.Embedding(len(word_vectors), embed_dim)\n",
    "    \n",
    "        self.GRU1 = torch.nn.GRU(self.embed_dim, latent_dim,  num_layers=1, batch_first = True)\n",
    "        self.GRU2 = torch.nn.GRU(self.embed_dim, latent_dim,  num_layers=1, batch_first = True)\n",
    "        \n",
    "        self.Projection_layer = torch.nn.Sequential(\n",
    "            torch.nn.Linear(latent_dim, len(word_vectors)),\n",
    "        )\n",
    "    def encoder_GRU(self, e_x):\n",
    "        e_y, hiddens = self.GRU1(e_x)\n",
    "        \n",
    "        return e_y, hiddens\n",
    "    \n",
    "    def decoder_GRU(self, d_x, hiddens):\n",
    "        d_y, hiddens2 = self.GRU2(d_x, hiddens)\n",
    "        return d_y, hiddens2\n",
    "    \n",
    "    def forward(self, e_x, d_x):\n",
    "        e_x = self.embedding(e_x).float()\n",
    "        \n",
    "        d_x = self.embedding(d_x).float()\n",
    "        \n",
    "        \n",
    "        e_y, hiddens = self.encoder_GRU(e_x)\n",
    "        \n",
    "        first = True\n",
    "        \n",
    "#         for word in d_x.transpose(1,0):\n",
    "#             word = word.view(word.shape[0], 1, -1)\n",
    "#             d_y, hiddens = self.decoder_GRU(word, hiddens)\n",
    "            \n",
    "# #             print(d_y.shape)\n",
    "#             if(first):\n",
    "#                 first = False;\n",
    "#                 last_layer_input = d_y\n",
    "#             else:\n",
    "#                 last_layer_input = torch.cat((last_layer_input, d_y), 1)\n",
    "#         #print(last_layer_input.shape)\n",
    "#         output = self.Projection_layer(last_layer_input)\n",
    "        for word in d_x.transpose(1,0):\n",
    "            word = word.view(word.shape[0], 1, -1)\n",
    "            d_y, hiddens = self.decoder_GRU(word, hiddens)\n",
    "            \n",
    "            if(first):\n",
    "                first = False;\n",
    "                last_layer_input = self.Projection_layer(d_y)\n",
    "            else:\n",
    "                last_layer_input = torch.cat((last_layer_input, self.Projection_layer(d_y)), 1)\n",
    "\n",
    "        output = last_layer_input\n",
    "        #print(output)\n",
    "        \n",
    "        return output\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttModel(torch.nn.Module):\n",
    "    def __init__(self, latent_dim, seq_length, embed_dim, word_vectors):\n",
    "        super(AttModel, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = latent_dim        \n",
    "        self.seq_length = seq_length\n",
    "        self.embed_dim = embed_dim\n",
    "        \n",
    "#         self.embedding = torch.nn.Embedding(len(word_vectors), embed_dim)\n",
    "#         self.embedding.load_state_dict({'weight': word_vectors})\n",
    "#         self.embedding.weight.requires_grad = False\n",
    "        self.embedding = torch.nn.Embedding.from_pretrained(torch.from_numpy(word_vectors), freeze=True)\n",
    "#        self.embedding = torch.nn.Embedding(len(word_vectors), embed_dim)\n",
    "    \n",
    "        self.soft = torch.nn.Softmax(-2)\n",
    "        \n",
    "        self.RNN1 = torch.nn.LSTM(self.embed_dim, latent_dim,  num_layers=2, batch_first = True)\n",
    "        self.RNN2 = torch.nn.LSTM(self.embed_dim, latent_dim,  num_layers=2, batch_first = True)\n",
    "        \n",
    "        self.Projection_layer = torch.nn.Sequential(\n",
    "            torch.nn.Linear(2 * latent_dim, len(word_vectors)),\n",
    "        )\n",
    "        \n",
    "        self.trainable_W = torch.nn.Sequential(\n",
    "            torch.nn.Linear(latent_dim ,  latent_dim),\n",
    "            torch.nn.Sigmoid(),\n",
    "            torch.nn.Dropout(p=0.2),\n",
    "        )\n",
    "    def encoder_RNN(self, e_x):\n",
    "        e_y, hiddens = self.RNN1(e_x)\n",
    "        \n",
    "        return e_y, hiddens\n",
    "    \n",
    "    def decoder_RNN(self, d_x, hiddens):\n",
    "        d_y, hiddens2 = self.RNN2(d_x, hiddens)\n",
    "        return d_y, hiddens2\n",
    "    \n",
    "    def forward(self, e_x, d_x, probs):\n",
    "        e_x = self.embedding(e_x).float()\n",
    "        \n",
    "        d_x = self.embedding(d_x).float()\n",
    "\n",
    "        #print(sent.shape) torch.Size([2, 15, 6087])\n",
    "\n",
    "        e_output, hiddens = self.encoder_RNN(e_x)\n",
    "        \n",
    "        #attention\n",
    "        uW = self.trainable_W(e_output)\n",
    "        \n",
    "        first = True\n",
    "        pre = None\n",
    "        for word in d_x.transpose(1,0):\n",
    "            #print(word.shape) torch.Size([2, 6087])\n",
    "            word = torch.unsqueeze(word , 1)\n",
    "            #torch.Size([128, 1, 100])\n",
    "            \n",
    "#             #sample a word here\n",
    "#             if (not first) and np.random.rand() < probs:\n",
    "#                 wordprob = self.Projection_layer(pre)\n",
    "#                 #print(wordprob.shape)torch.Size([128, 1, 46801])\n",
    "#                 ans_indices = torch.argmax(wordprob, dim=-1, keepdim=False)\n",
    "#                 word = self.embedding(ans_indices).float()\n",
    "#                 #torch.Size([128, 1, 100])\n",
    "            \n",
    "            #or randomize for each data in batch\n",
    "            if not first:\n",
    "                useTeacher = (torch.rand(word.shape[0]) > probs).float().view(-1, 1, 1).to(device)\n",
    "                useSample = 1.0 - useTeacher\n",
    "                \n",
    "                #get previous output\n",
    "                wordprob = self.Projection_layer(pre)\n",
    "                ans_indices = torch.argmax(wordprob, dim=-1, keepdim=False)\n",
    "                preword = self.embedding(ans_indices).float()\n",
    "                \n",
    "                #mixture\n",
    "                word = useTeacher*word + useSample*preword\n",
    "                \n",
    "                \n",
    "                \n",
    "            \n",
    "\n",
    "            #print(word.shape)\n",
    "            #one for each word, therefore d_output = d_state\n",
    "            d_output, hiddens = self.decoder_RNN(word, hiddens)\n",
    "            uWv = torch.matmul(uW, d_output.transpose(2,1))\n",
    "            #print(uWv.shape) torch.Size([2, 80, 1])\n",
    "            alpha = self.soft(uWv)\n",
    "            #print(uWv)\n",
    "            #print(alpha)\n",
    "            #input(\"\")\n",
    "            new_context = e_output.transpose(2,1) @ alpha;\n",
    "            #print(e_output.shape) torch.Size([2, 80, 256])\n",
    "            #print(alpha.shape) torch.Size([2, 80, 1])\n",
    "            \n",
    "            #print(d_output.shape) torch.Size([2, 1, 256])\n",
    "            #print(new_context.shape) torch.Size([2, 256, 1])          \n",
    "            pre = torch.cat((d_output, new_context.transpose(2,1)), 2)\n",
    "            if(first):\n",
    "                first = 0;\n",
    "                last_layer_input = pre\n",
    "            else:\n",
    "                last_layer_input = torch.cat((last_layer_input, pre), 1)\n",
    "            #print(last_layer_input.shape) #torch.Size([2, 1, 512])\n",
    "            \n",
    "        logits = self.Projection_layer(last_layer_input)\n",
    "\n",
    "        #logits = torch.stack(logits, 1)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46801, 100)\n"
     ]
    }
   ],
   "source": [
    "#hyperparameters\n",
    "lr = 5e-3  # learning rate\n",
    "batch_size = 256\n",
    "latent_dim = 1024\n",
    "iter_in_epoch = 500\n",
    "embed_dim = word_vectors.shape[1]\n",
    "print(word_vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 62\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9145f3c0b5474fa08f7dfbd24fedcfdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train', max=3440, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['你', '是', '對', '的', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "['你', '是', '<eos>', '的', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>']\n",
      "tensor(1.0865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "['說', '的', '夠多', '了', ',', '我們', '要', '走', '了', '<eos>']\n",
      "['說', '的', '夠多', '了', ',', '我們', '要', '走', '了', '<eos>']\n",
      "tensor(1.2415, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss: 1.1091374323811642\n",
      "loss=1.109518\n",
      "\n",
      "training 63\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c553f94430204edeb55f077b16a04792",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train', max=3440, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['幾分鐘', '後', '便', '知道', '結果', '如何', '了', '<eos>', '<pad>', '<pad>']\n",
      "['幾分鐘', '後', '便', '知道', '結果', '如何', '了', '<eos>', '<eos>', '<eos>']\n",
      "tensor(1.1674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "['我', '認為', '我', '只', '聽到', '喬治', '<eos>', '<pad>', '<pad>', '<pad>']\n",
      "['我要', '認為', '那', '正', '發生', '。', '<eos>', '<eos>', '<eos>', '<eos>']\n",
      "tensor(1.2182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss: 1.0989156585966438\n",
      "loss=1.099264\n",
      "\n",
      "training 64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "603740d6f7ea4e388b0dc39fade202dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train', max=3440, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['五天', '的', '誘惑', '永久', '的', '沉睡', '<eos>', '<pad>', '<pad>', '<pad>']\n",
      "['五天', '的', '誘惑', '永久', '的', '沉睡', '中', '<eos>', '<eos>', '<eos>']\n",
      "tensor(1.0045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "['我', '認識', '很多', '毒販', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "['我', '的', '很多', '毒販', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>']\n",
      "tensor(1.0294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss: 1.0898553813092933\n",
      "loss=1.090272\n",
      "\n",
      "training 65\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15db288734954664abb4375cbae0ae5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train', max=3440, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['我', '也', '想', '知道', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "['我', '也', '想', '知道', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>']\n",
      "tensor(1.0931, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "['沒有', ',', '沒', '懷孕', '過', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "['沒有', ',', '沒', '懷孕', '過', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>']\n",
      "tensor(1.3520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss: 1.0822724126799161\n",
      "loss=1.082655\n",
      "\n",
      "training 66\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78bdcee2b6f74bd799651ca6e4932903",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train', max=3440, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['不', '我', '想', '說', '好', '啊', '我', '是', '說', '<eos>']\n",
      "['不', '我', '好', '說', '說', '好', '好', '啊', '啊', '好']\n",
      "tensor(1.1568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "['好', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "['好', '<eos>', '<eos>', '對', '對', '我們', '<eos>', '<eos>', '<eos>', '<eos>']\n",
      "tensor(1.1510, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss: 1.0725580528205216\n",
      "loss=1.072904\n",
      "\n",
      "training 67\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad8ec09ff2e346e688de7fcf60405a6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train', max=3440, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['女孩', '從', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "['你', '<eos>', '布朗', '克斯', '?', '<eos>', '<eos>', '?', '<eos>', '<eos>']\n",
      "tensor(1.1522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "['看看', '我們', '今天', '掙', '了', '多少', '<eos>', '<pad>', '<pad>', '<pad>']\n",
      "['我', '<eos>', '<eos>', '掙', '了', '多少', '<eos>', '<eos>', '<eos>', '<eos>']\n",
      "tensor(1.1874, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss: 1.0664290095137996\n",
      "loss=1.066793\n",
      "\n",
      "training 68\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76279fcc106f4b3085ec094a4a4dc536",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train', max=3440, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['不', '可能', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "['不', '不', '不是', '不是', '她們', '的', '女朋友', '<eos>', '<eos>', '<eos>']\n",
      "tensor(1.0263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "['對', '收音機', '我', '的', '指揮官', '。', '。', '。', '<eos>', '<pad>']\n",
      "['對', '收音機', '我', '來說', '。', '<eos>', '。', '<eos>', '<eos>', '<eos>']\n",
      "tensor(1.2444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss: 1.0566822513071603\n",
      "loss=1.057008\n",
      "\n",
      "training 69\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee900e1234c44bf99fc95b47da5f33d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train', max=3440, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['他們', '正是', '抒情詩', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "['他們', '正是', '抒情詩', '。', '<eos>', '。', '<eos>', '<eos>', '。', '<eos>']\n",
      "tensor(1.1120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "['啊', ',', '可以', '讓', '我', '過去', '一下', '嗎', '?', '<eos>']\n",
      "['是', '他', '可以', '買', '一個', '的', '房子', '<eos>', '?', '<eos>']\n",
      "tensor(1.2884, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss: 1.0494221971132034\n",
      "loss=1.049807\n",
      "\n",
      "training 70\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d503291d8874219a1c588f44b9b5b3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train', max=3440, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['病毒', '會發', '心臟病', '的', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "['病毒', '會發', '心臟病', '的', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>']\n",
      "tensor(1.1319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "['你', '看看', ',', '好', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "['你', '看看', ',', '這', '了', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>']\n",
      "tensor(1.1762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss: 1.0427168343476085\n",
      "loss=1.043048\n",
      "\n",
      "training 71\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59865581a10d4f49aa70d75c5a77b95b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train', max=3440, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['可惜', '你', '打扮', '得', '再', '美', '<eos>', '<pad>', '<pad>', '<pad>']\n",
      "['可惜', '你', '打扮', '得', '再', '美', '<eos>', '<eos>', '<eos>', '<eos>']\n",
      "tensor(0.9580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "['爲', '你', '被', '<unk>', '像', '你', '<eos>', '<pad>', '<pad>', '<pad>']\n",
      "['爲', '你', '被', '<unk>', '爲', '像', '<eos>', '<eos>', '<eos>', '<eos>']\n",
      "tensor(1.2190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss: 1.0367222321587939\n",
      "loss=1.037060\n",
      "\n",
      "training 72\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0807732c13f04688926d733affab0e7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train', max=3440, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['首先', '它', '太大', '了', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "['不行', '它', '太大', '了', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>']\n",
      "tensor(1.2257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "['<unk>', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "['我們', '知道', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>']\n",
      "tensor(1.0393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss: 1.0288436462712842\n",
      "loss=1.029163\n",
      "\n",
      "training 73\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc9bc73b260b40aa9401cd6ed3cfa954",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train', max=3440, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['大家', '都', '說', '這種', '肥皂', '最好', '用', '<eos>', '<pad>', '<pad>']\n",
      "['大家', '都', '這種', '這種', '肥皂', '最好', '用', '<eos>', '<eos>', '<eos>']\n",
      "tensor(1.0969, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "['怎麼', '打扮', '成', '這樣', '?', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "['怎麼', '打扮', '的', '這樣', '?', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>']\n",
      "tensor(1.1484, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss: 1.0207240452773355\n",
      "loss=1.021026\n",
      "\n",
      "training 74\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ee1037ae09a4c9ca9090009a7134d5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train', max=3440, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['然後', '教', '我', '拳擊', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "['然後', '教', '我', '拳擊', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>']\n",
      "tensor(1.2555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "['等', '一下', ',', '是', '你', '偵測', '到', '的', '?', '<eos>']\n",
      "['等', '一下', ',', '是', '你', '偵測', '到', '的', '?', '<eos>']\n",
      "tensor(1.2477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss: 1.0148682394693065\n",
      "loss=1.015222\n",
      "\n",
      "training 75\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c4ddce5a7eb44609efa198123dae73d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train', max=3440, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['叫', '他', '別', '扯', '我', '進來', '<eos>', '<pad>', '<pad>', '<pad>']\n",
      "['叫', '他', '別', '拿', '我', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>']\n",
      "tensor(0.9712, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "['等', '我', '把', '帽子', '摘下來', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "['等', '我', '把', '帽子', '摘下來', ',', '<eos>', '吧', '<eos>', '<eos>']\n",
      "tensor(1.0077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss: 1.0076145511033923\n",
      "loss=1.007940\n",
      "\n",
      "training 76\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfbc95a3aa8f45e891c2b1b534bee9c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train', max=3440, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['男孩', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "['男孩', '的', '一個', '女孩', '做', '的', '比賽', '<eos>', '<eos>', '<eos>']\n",
      "tensor(1.0557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "['然後', '每週', '都', '要', '吹', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "['然後', '每週', '都', '吹', '吹', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>']\n",
      "tensor(1.1812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss: 1.0032601992404737\n",
      "loss=1.003584\n",
      "\n",
      "training 77\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2823d87badd47b596cc70011f90dd0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train', max=3440, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['我們', '下次', '再說', '吧', ',', '謝謝', '<eos>', '<pad>', '<pad>', '<pad>']\n",
      "['我們', '下次', '再說', '吧', '謝謝', '謝謝', '<eos>', '<eos>', '<eos>', '<eos>']\n",
      "tensor(0.9020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "['嘿', ',', '我們', '去', '哪兒', '?', '<eos>', '<pad>', '<pad>', '<pad>']\n",
      "['曾', ',', '卻', '被', '祖國', '?', '<eos>', '<eos>', '<eos>', '<eos>']\n",
      "tensor(0.9545, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss: 0.9958086816723957\n",
      "loss=0.996087\n",
      "\n",
      "training 78\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eb3f187254842debf777dac780dc776",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train', max=3440, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['你', '知道', '自己', '在', '說', '什麼', '?', '<eos>', '<pad>', '<pad>']\n",
      "['你', '知道', '自己', '在', '說', '什麼', '嗎', '<eos>', '<eos>', '<eos>']\n",
      "tensor(0.8936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "['什麼', '你', '看不到', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "['去', ',', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>']\n",
      "tensor(1.0849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss: 0.9903046908766724\n",
      "loss=0.990569\n",
      "\n",
      "training 79\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df9ead8113e14041a395af6b6763df4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train', max=3440, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['只要', '往後', '拉', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "['我', '了', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>']\n",
      "tensor(0.8929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "['你們', '處理', '這個', '案子', '的', '手法', '<eos>', '<pad>', '<pad>', '<pad>']\n",
      "['我', '來得', ',', '案子', '造福', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>']\n",
      "tensor(0.8871, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss: 0.9839016861000727\n",
      "loss=0.984244\n",
      "\n",
      "training 80\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3212c4f65b6542b486d4965604b166d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train', max=3440, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['都', '同意', '簽署', '和平', '協議', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "['都', '同意', '簽署', '和平', '協議', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>']\n",
      "tensor(1.1170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "['哦', ',', '大家', '都', '喜歡', '聽', '寵物', '故事', '<eos>', '<pad>']\n",
      "['哦', ',', '大家', '都', '喜歡', '聽', '寵物', '故事', '<eos>', '<eos>']\n",
      "tensor(1.0598, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss: 0.9784244436337505\n",
      "loss=0.978701\n",
      "\n",
      "training 81\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ff22dead7e54af1b7b86ff3da0a7913",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train', max=3440, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['你', '沒有', '感覺', '嗎', '?', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "['你', '沒有', '感覺', '嗎', '?', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>']\n",
      "tensor(0.8626, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "['你', '會', '怎麼', '做', '?', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "['你', '會', '怎麼', '說', '?', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>']\n",
      "tensor(1.1661, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss: 0.9730849147536034\n",
      "loss=0.973380\n",
      "\n",
      "training 82\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c41c9cefd7942508a55c8a5b4f8c5fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train', max=3440, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['還好', '麼', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "['還好', '麼', '<eos>', '<eos>', '<eos>', '<eos>', '吹', '<eos>', '<eos>', '<eos>']\n",
      "tensor(0.9935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "['但', '不許', '碰', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "['你', '我', '不', '你', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>']\n",
      "tensor(1.0112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "loss: 0.9663721536134564\n",
      "loss=0.966696\n",
      "\n",
      "training 83\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "800d168b1f0f4020842807e21861d39b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train', max=3440, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.8369893600863795\r"
     ]
    }
   ],
   "source": [
    "model = AttModel(latent_dim, sent_len, embed_dim, word_vectors)\n",
    "saved_model = torch.load(\"models/Model61\")\n",
    "model.load_state_dict(saved_model['model'])\n",
    "\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=lr)\n",
    "optimizer.load_state_dict(saved_model['optimizer'])\n",
    "loss_function = torch.nn.CrossEntropyLoss(ignore_index=DIC_word_index['<pad>'])\n",
    "\n",
    "epoch = saved_model['epoch']\n",
    "max_epochs = 100  # how many epochs to train for\n",
    "while epoch < max_epochs:\n",
    "    # train and evaluate train score\n",
    "    print('training %i' % epoch)\n",
    "\n",
    "    # train epoch\n",
    "    dataloader = torch.utils.data.DataLoader(datas, batch_size = batch_size, shuffle = True, collate_fn = my_collate)\n",
    "    log_train = _run_epoch(dataloader, True, model, optimizer, loss_function)\n",
    "\n",
    "    # test epoch\n",
    "    \"\"\"\n",
    "    print('evaluating %i' % epoch)\n",
    "    dataloader = torch.utils.data.DataLoader(valid_datas, batch_size = batch_size, collate_fn=my_collate)\n",
    "    log_valid = _run_epoch(dataloader, False, model, optimizer, loss_function)\n",
    "    \"\"\"\n",
    "    \n",
    "    epoch += 1\n",
    "    if epoch % 5 == 0:\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'model': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict()\n",
    "        }, \"./models/Model\" + str(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'model': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict()\n",
    "        }, \"./models/Model\" + str(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = SimpleRNN(latent_dim, sent_len, embed_dim, word_vectors)\n",
    "model = AttModel(latent_dim, sent_len, embed_dim, word_vectors)\n",
    "\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=lr)\n",
    "loss_function = torch.nn.CrossEntropyLoss(ignore_index=DIC_word_index['<pad>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "epoch = 0;\n",
    "max_epochs = 100  # how many epochs to train for\n",
    "while epoch < max_epochs:\n",
    "    # train and evaluate train score\n",
    "    print('training %i' % epoch)\n",
    "\n",
    "    # train epoch\n",
    "    dataloader = torch.utils.data.DataLoader(datas, batch_size = batch_size, shuffle = True, collate_fn = my_collate)\n",
    "    log_train = _run_epoch(dataloader, True, model, optimizer, loss_function)\n",
    "\n",
    "    # test epoch\n",
    "    \"\"\"\n",
    "    print('evaluating %i' % epoch)\n",
    "    dataloader = torch.utils.data.DataLoader(valid_datas, batch_size = batch_size, collate_fn=my_collate)\n",
    "    log_valid = _run_epoch(dataloader, False, model, optimizer, loss_function)\n",
    "    \"\"\"\n",
    "    \n",
    "    epoch += 1\n",
    "    torch.save({\n",
    "        'epoch': epoch + 1,\n",
    "        'model': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict()\n",
    "    }, \"./models/Model\" + str(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(DIC_word_index['<pad>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
